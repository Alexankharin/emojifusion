{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12423/2760596834.py:3: FutureWarning: set_caching_enabled is deprecated and will be removed in the next major version of datasets. Use datasets.enable_caching() or datasets.disable_caching() instead. This function will be removed in a future version of datasets.\n",
      "  set_caching_enabled(False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ad88a4a8d1484cae32d57e1ede6e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/555 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import set_caching_enabled\n",
    "set_caching_enabled(False)\n",
    "data_dir=\"../data/emojis/barepng\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=data_dir)\n",
    "#dataset['train']=dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image'],\n",
       "        num_rows: 555\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "imglist=os.listdir(data_dir)\n",
    "imglist.sort()\n",
    "emojidict=json.loads(open('../data/emojidict.json').read())\n",
    "texts=[emojidict[k.split('.')[0]].replace('_',' ') for k in imglist]\n",
    "##from PIL import Image\n",
    "##Image.open(f'../data/emojis/barepng/{imglist[0]}')\n",
    "#texts=\n",
    "dataset['train']=dataset['train'].add_column(name='text',column=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The table can't have duplicated columns but columns ['text'] are duplicated.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/emojifusion/notebooks/2. prepare_dataset.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B92.239.201.129/workspace/emojifusion/notebooks/2.%20prepare_dataset.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mdataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49madd_column(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m,column\u001b[39m=\u001b[39;49mtexts)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/fingerprint.py:511\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    509\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m out \u001b[39m=\u001b[39m func(dataset, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    513\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:5618\u001b[0m, in \u001b[0;36mDataset.add_column\u001b[0;34m(self, name, column, new_fingerprint)\u001b[0m\n\u001b[1;32m   5591\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Add column to Dataset.\u001b[39;00m\n\u001b[1;32m   5592\u001b[0m \n\u001b[1;32m   5593\u001b[0m \u001b[39m<Added version=\"1.7\"/>\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5615\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   5616\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5617\u001b[0m column_table \u001b[39m=\u001b[39m InMemoryTable\u001b[39m.\u001b[39mfrom_pydict({name: column})\n\u001b[0;32m-> 5618\u001b[0m _check_column_names(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49mcolumn_names \u001b[39m+\u001b[39;49m column_table\u001b[39m.\u001b[39;49mcolumn_names)\n\u001b[1;32m   5619\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten_indices() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m   5620\u001b[0m \u001b[39m# Concatenate tables horizontally\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:644\u001b[0m, in \u001b[0;36m_check_column_names\u001b[0;34m(column_names)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(count \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m count \u001b[39min\u001b[39;00m counter\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    643\u001b[0m     duplicated_columns \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m counter \u001b[39mif\u001b[39;00m counter[col] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 644\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe table can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have duplicated columns but columns \u001b[39m\u001b[39m{\u001b[39;00mduplicated_columns\u001b[39m}\u001b[39;00m\u001b[39m are duplicated.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The table can't have duplicated columns but columns ['text'] are duplicated."
     ]
    }
   ],
   "source": [
    "dataset['train']=dataset['train'].add_column(name='text',column=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51401b2d1dd34299b3ac320a0ede7717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/555 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/emojis/emojisdescr.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=datasets.Dataset.from_file('../data/emojis/emojisdescr.hf/train/data-00000-of-00001.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 555\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= datasets.load_dataset(\n",
    "           '../data/emojis/emojisdescr.hf',\n",
    "            args.dataset_config_name,\n",
    "            cache_dir=args.cache_dir,\n",
    "            data_dir=args.train_data_dir,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
